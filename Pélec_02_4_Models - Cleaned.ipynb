{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir exploré et nettoyé le dataset, nous allons effectuer des étapes de préparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- flake8 pour vérifier PEP8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext pycodestyle_magic\n",
    "# %flake8_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- imports des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "# settings\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les données\n",
    "raw = pd.read_csv('prep.csv')\n",
    "print(raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Appliquer (ou non) une restriction des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appliquer la séléction \"stricte\"\n",
    "sel = raw[~(((raw['LargestPropertyUseType'] == 'Multifamily Housing') & (\n",
    "    (raw['SecondLargestPropertyUseType'] == 'None')) |\n",
    "    (raw['SecondLargestPropertyUseType'] == 'Parking')) & (\n",
    "    (raw['ThirdLargestPropertyUseType'] == 'None')))]\n",
    "print(sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ne pas appliquer de sélection \n",
    "sel = raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features de résultats : 4 cibles possibles\n",
    "Results = ['SiteEUI(kBtu/sf)',\n",
    "           'SiteEnergyUse(kBtu)',\n",
    "           'TotalGHGEmissions',\n",
    "           'GHGEmissionsIntensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirer les outliers\n",
    "for i in Results:\n",
    "    sel = sel[sel[i] <= sel[i].quantile(0.99)]\n",
    "    sel = sel[sel[i] >= sel[i].quantile(0.01)]\n",
    "    print(sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compter le nombre de données manquantes pour l'ESS\n",
    "sel['ENERGYSTARScore'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- le test de prise en compte de l'ENERGYSTARScore impliquera d'opérer une restriction supplémentaire sur les données, donc jouer les modèles pour ajouter une référence avec et calculer l'apport de l'ENERGYSTARScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opérer si nécessaire une sélection supplémentaire des données :\n",
    "# entre 2015 et 2016, avec ou sans valeurs par défauts, avec ou sans outliers.\n",
    "Select_features = ['OSEBuildingID',\n",
    "                   'DataYear',\n",
    "                   'Select_Default',\n",
    "                   'Select_Outlier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Sélectionner la cible et des features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pour rappel 3 catégories de features ont été crées : <br/>\n",
    "Features_OH, suite One Hot Encoding des données catégorielles, <br/>\n",
    "Features_RG, suite au traitement des données numériques, <br/>\n",
    "et Features_UseType, suite au calcul de la proportion de type d'usage - qualitatif. <br/>\n",
    "en plus des features dérivés (pseudo-numériques)<br/>\n",
    "N_D_features = ['N_D_hasNaturalGas', 'N_D_hasSteam', 'N_D_NbPropUseRange', 'N_D_NbofBuildingsRange', 'N_D_NbofFloorsRange','N_D_BuildingType']\n",
    "\n",
    "Le principe retenu est de : <br/>\n",
    "- sélectionner les features à prendre en compte dans le modèle, avec Energystar score le cas échéant \n",
    "    - sel_features\n",
    "- sélectioner la méthode de stratification<br/>\n",
    "    - 'N_BuildingType' (une piste serait de tester aussi 'N_PrimaryPropertyType')\n",
    "- jouer le modèle sur chacune des cibles parmi les 4 possibles (boucle for) <br/>\n",
    "    - sel_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fonction d'évaluation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction d'évaluation d'un modèle\n",
    "# entrainement, prédictions, calcul des scores et affichage predict vs test\n",
    "\n",
    "def evaluate(model_name,\n",
    "             model,\n",
    "             data,\n",
    "             sel_features,\n",
    "             sel_target,\n",
    "             split_size,\n",
    "             stratif,\n",
    "             imp):\n",
    "\n",
    "    # sélection des features et de la cible\n",
    "    features = data[sel_features]\n",
    "    # passage au log de la cible\n",
    "    labels = np.log(data[sel_target])\n",
    "\n",
    "    # split\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features,\n",
    "        labels,\n",
    "        test_size=split_size,\n",
    "        random_state=42,\n",
    "        stratify=data[stratif])\n",
    "\n",
    "    # entrainement du modèle\n",
    "    model.fit(train_features, train_labels)\n",
    "\n",
    "    # calcul des predictions\n",
    "    predictions = model.predict(test_features)\n",
    "\n",
    "    # retour aux valeurs d'origine\n",
    "    test = np.exp(test_labels)\n",
    "    predict = np.exp(predictions)\n",
    "\n",
    "    # évaluation selon r2 et rmse\n",
    "    r2 = r2_score(test, predict)\n",
    "    rmse = np.sqrt(\n",
    "        metrics.mean_squared_error(\n",
    "            test,\n",
    "            predict))\n",
    "    mae = mean_absolute_error(test, predict)\n",
    "\n",
    "    # affichage Test vs Predictions\n",
    "    g = sns.jointplot(\n",
    "        test,\n",
    "        predict,\n",
    "        kind='reg',\n",
    "        stat_func=r2_score)\n",
    "    g.ax_joint.set_xlabel(sel_target + ' - test')\n",
    "    g.ax_joint.set_ylabel(sel_target + ' - predicted')\n",
    "    g.fig.suptitle(t='Test vs Prediction for: '\n",
    "                   + str(sel_target)\n",
    "                   + '\\n'\n",
    "                   + 'Model: '\n",
    "                   + str(model).split('(')[0]\n",
    "                   + ' - '\n",
    "                   + str(model_name),\n",
    "                   y=0,\n",
    "                   fontsize=16,\n",
    "                   alpha=0.75,\n",
    "                   weight='bold',\n",
    "                   ha='center')\n",
    "    x0, x1 = g.ax_joint.get_xlim()\n",
    "    y0, y1 = g.ax_joint.get_ylim()\n",
    "    lims = [max(x0, y0), min(x1, y1)]\n",
    "    g.ax_joint.plot(lims, lims, ':k')\n",
    "    plt.show()\n",
    "\n",
    "    # affichage des scores et des paramètres du modèle\n",
    "    print('r2: {:.2f}'.format(r2))\n",
    "    print('rmse : {:.2f}'.format(rmse))\n",
    "    print('mae : {:.2f}'.format(mae))\n",
    "    print(str(model).split('(')[0])\n",
    "    pprint(model.get_params())\n",
    "\n",
    "    # affichage des erreurs\n",
    "    df_res = pd.DataFrame({'true': test, 'pred': predict})\n",
    "    df_res = df_res.sort_values('true')\n",
    "\n",
    "    plt.plot(df_res['pred'].values, label='pred')\n",
    "    plt.plot(df_res['true'].values, label='true')\n",
    "    plt.xlabel('Test sample')\n",
    "    plt.ylabel(sel_target)\n",
    "    plt.suptitle(t='Error display for: '\n",
    "                   + str(sel_target)\n",
    "                   + '\\n'\n",
    "                   + 'Model: '\n",
    "                   + str(model).split('(')[0]\n",
    "                   + ' - '\n",
    "                   + str(model_name),\n",
    "                   y=0,\n",
    "                   fontsize=16,\n",
    "                   alpha=0.75,\n",
    "                   weight='bold',\n",
    "                   ha='center')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # affichage des features importance si option\n",
    "    if imp == 1:\n",
    "        feat_imp(model)\n",
    "\n",
    "    # affichage de la valeur max prédite\n",
    "    \n",
    "        \n",
    "    return r2, rmse, mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction d'affichage des features importance d'un model randomforest\n",
    "\n",
    "def feat_imp(rf_model):\n",
    "    feature_importances = rf_model.feature_importances_\n",
    "    temp = {\n",
    "        'feature_names': sel_features,\n",
    "        'feature_importances': feature_importances\n",
    "    }\n",
    "    temp = pd.DataFrame(temp).sort_values(by='feature_importances',\n",
    "                                          ascending=False)\n",
    "    display(temp.tail(30))\n",
    "\n",
    "    scree = temp.feature_importances*100\n",
    "    plt.bar(np.arange(len(scree))+1, scree)\n",
    "    plt.plot(np.arange(len(scree))+1, scree.cumsum(), c=\"red\", marker='o')\n",
    "    plt.xlabel('features classés par importance décroissante')\n",
    "    plt.ylabel('importance')\n",
    "    plt.title('distribution des features importance')\n",
    "    plt.show(block=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Définir le scope (features pris en compte et cible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélectionner les arguments de la fonction d'évaluation\n",
    "# les features dérivés et les features numériques traités\n",
    "sel_features = sel.columns[\n",
    "    sel.columns.str.contains('N_RG_') |\n",
    "    sel.columns.str.contains('N_D_')]\n",
    "print(sel_features.size)\n",
    "# la cible prise en référence est \n",
    "sel_target = 'SiteEnergyUse(kBtu)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modèles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Dummy Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer une référence approche naïve par la moyenne\n",
    "dummy_regr = DummyRegressor(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# afficher les scores et prédictions vs test associées\n",
    "for i in Results:\n",
    "    dummy_score = evaluate('dummy_regr',\n",
    "                           dummy_regr,\n",
    "                           sel,\n",
    "                           sel_features,\n",
    "                           i,\n",
    "                           0.25,\n",
    "                           'N_D_BuildingType',\n",
    "                           0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Base Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer une référence \n",
    "base_rf = RandomForestRegressor(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# afficher les scores et prédictions vs test associées\n",
    "for i in Results:\n",
    "    base_rf_score = evaluate('base_rf', base_rf, sel, sel_features, i, 0.25, 'N_D_BuildingType', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Randomized Search CV >> BEST MODEL <<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# définition des plages de variation des hyperparamètres\n",
    "n_estimators = [int(x) for x in np.linspace(start=300, stop=500, num=3)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(130, 190, num=7)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 3]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la grid : random_grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélection des features et de la cible (une seule cible)\n",
    "features = sel[sel_features]\n",
    "labels = np.log(sel[sel_target])\n",
    "\n",
    "# split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=sel['N_D_BuildingType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer d'un modèle et RandomizedSearchCV des hyperparamètres\n",
    "# avec 3 folds de cross validation\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator=rf,\n",
    "                               param_distributions=random_grid,\n",
    "                               n_iter=100,\n",
    "                               cv=3,\n",
    "                               verbose=2,\n",
    "                               random_state=42,\n",
    "                               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entraîneer le modèle pour déterminer les meilleurs paramètres\n",
    "rf_random.fit(train_features, train_labels)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# appliquer les meilleurs paramètres\n",
    "best_random = rf_random.best_estimator_\n",
    "random_score = evaluate('best_random', best_random, sel, sel_features, sel_target, 0.25, 'N_D_BuildingType', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définir les paramètres pour un GridSearch CV\n",
    "param_grid = {'bootstrap': [False],\n",
    "              'max_depth': [140, 150, 160],\n",
    "              'max_features': ['sqrt'],\n",
    "              'min_samples_leaf': [1],\n",
    "              'min_samples_split': [3],\n",
    "              'n_estimators': [200, 300, 400]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un model de base rf\n",
    "rf = RandomForestRegressor()\n",
    "# paramètrer le GridSearch, avec 3 folds\n",
    "rf_grid_search = GridSearchCV(estimator=rf,\n",
    "                              param_grid=param_grid,\n",
    "                              cv=3,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# entraînement du modèle pour déterminer les meilleurs paramètres\n",
    "rf_grid_search.fit(train_features, train_labels)\n",
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# application des meilleurs paramètres\n",
    "rf_best_grid = rf_grid_search.best_estimator_\n",
    "best_grid_score = evaluate('rf_best_grid', rf_best_grid, sel, sel_features, sel_target, 0.25, 'N_D_BuildingType', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. Linear Regression - base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un modèle de régression linéaire\n",
    "base_lr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# afficher les scores et prédictions vs test associées\n",
    "for i in Results:\n",
    "    base_lr_score = evaluate('base_lr',\n",
    "                             base_lr,\n",
    "                             sel,\n",
    "                             sel_features,\n",
    "                             i,\n",
    "                             0.25,\n",
    "                             'N_D_BuildingType',\n",
    "                             0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6. Ridge avec Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un modèle ridge with CV\n",
    "ridgeCV = linear_model.RidgeCV(alphas=np.logspace(-1, 6, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrainer le ridge CV dans les mêms conditions que le random forest\n",
    "model_cv = ridgeCV.fit(train_features, train_labels)\n",
    "model_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridgeCV = linear_model.Ridge(alpha=model_cv.alpha_)\n",
    "best_ridgeCV_score = evaluate('best_ridgeCV', best_ridgeCV, sel, sel_features, sel_target, 0.25, 'N_D_BuildingType', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7. Lasso avec Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le lasso\n",
    "LassoCV = linear_model.LassoCV(alphas=np.logspace(-5, 2, 200), fit_intercept=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrainer le ridge CV dans les mêms conditions que le random forest\n",
    "LassoCv_mdl = LassoCV.fit(train_features, train_labels)\n",
    "LassoCv_mdl.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_LassoCV = linear_model.Lasso(alpha=LassoCv_mdl.alpha_)\n",
    "best_LassoCV_score = evaluate('best_LassoCV', best_LassoCV, sel, sel_features, sel_target, 0.25, 'N_D_BuildingType', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation de l'intérêt de l'EnergyStar Score dans les prédiction d'émissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cette section compare les modèles avec ou sans prise en compte du feature EnergyStar Score. \n",
    "- l'apport est réel mais pas flagrant 5 % d'amélioration du R2, et d'autant moindre qu'il y a de feature (et feature engineering) pris en compte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retourner aux données initiales\n",
    "sel = raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features de résultats : 4 cibles possibles\n",
    "Results = ['SiteEUI(kBtu/sf)',\n",
    "           'SiteEnergyUse(kBtu)',\n",
    "           'TotalGHGEmissions',\n",
    "           'GHGEmissionsIntensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirer les outliers\n",
    "for i in Results:\n",
    "    sel = sel[sel[i] <= sel[i].quantile(0.99)]\n",
    "    sel = sel[sel[i] >= sel[i].quantile(0.01)]\n",
    "    print(sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compter le nombre de données manquantes pour l'ESS\n",
    "sel['ENERGYSTARScore'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.dropna(axis=0, subset=['ENERGYSTARScore'], inplace=True)\n",
    "sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélectionner les arguments de la fonction d'évaluation\n",
    "# les features dérivés et les features numériques traités\n",
    "sel_features = sel.columns[\n",
    "    sel.columns.str.contains('N_RG_') |\n",
    "    sel.columns.str.contains('N_D_') |\n",
    "    sel.columns.str.contains('N_OH_')]\n",
    "print(sel_features.size)\n",
    "# la cible prise en référence est \n",
    "sel_target = 'TotalGHGEmissions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# évaluer un randomforest sur ce scope sans l'ESS\n",
    "base_rf_woESS = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "base_rf_woESS_score = evaluate('base_rf_woESS',\n",
    "                               base_rf_woESS,\n",
    "                               sel,\n",
    "                               sel_features,\n",
    "                               'GHGEmissionsIntensity',\n",
    "                               0.25,\n",
    "                               'N_D_BuildingType',\n",
    "                               1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajouter l'EnergyStar Score\n",
    "sel_features = sel_features.append(sel.columns.intersection(['ENERGYSTARScore']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# évaluer un randomforest sur ce scope avec ESS\n",
    "base_rf_wiESS = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "base_rf_wiESS_score = evaluate('base_rf_wiESS',\n",
    "                               base_rf_wiESS,\n",
    "                               sel,\n",
    "                               sel_features,\n",
    "                               'GHGEmissionsIntensity',\n",
    "                               0.25,\n",
    "                               'N_D_BuildingType',\n",
    "                               1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'- le gain avec l'ESS n'est pas vraiment significatif sur cette base, on évalue également ce que ce feature peut apporter dans le cas d'un Randomized Search with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# définition des plages de variation des hyperparamètres\n",
    "n_estimators = [int(x) for x in np.linspace(start=300, stop=500, num=3)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(130, 190, num=7)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 3]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la grid : random_grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélectionner les arguments de la fonction d'évaluation\n",
    "# les features dérivés et les features numériques traités\n",
    "sel_features = sel.columns[\n",
    "    sel.columns.str.contains('N_RG_') |\n",
    "    sel.columns.str.contains('N_D_') |\n",
    "    sel.columns.str.contains('N_OH_')]\n",
    "print(sel_features.size)\n",
    "# la cible prise en référence est \n",
    "sel_target = 'TotalGHGEmissions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélection des features et de la cible (une seule cible)\n",
    "features = sel[sel_features]\n",
    "labels = np.log(sel[sel_target])\n",
    "\n",
    "# split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=sel['N_D_BuildingType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer d'un modèle et RandomizedSearchCV des hyperparamètres\n",
    "# avec 3 folds de cross validation\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator=rf,\n",
    "                               param_distributions=random_grid,\n",
    "                               n_iter=100,\n",
    "                               cv=3,\n",
    "                               verbose=2,\n",
    "                               random_state=42,\n",
    "                               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entraîner le modèle pour déterminer les meilleurs paramètres\n",
    "rf_random.fit(train_features, train_labels)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# appliquer les meilleurs paramètres\n",
    "best_random = rf_random.best_estimator_\n",
    "random_score = evaluate('best_random', best_random, sel, sel_features, sel_target, 0.25, 'N_D_BuildingType', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Gradient Boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélectionner les arguments de la fonction d'évaluation\n",
    "# les features dérivés et les features numériques traités\n",
    "sel_features = sel.columns[\n",
    "    sel.columns.str.contains('N_RG_') |\n",
    "    sel.columns.str.contains('N_D_') |\n",
    "    sel.columns.str.contains('N_OH_')]\n",
    "print(sel_features.size)\n",
    "# la cible prise en référence est \n",
    "sel_target = 'SiteEnergyUse(kBtu)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un modèle GBM\n",
    "GBM_base = GradientBoostingRegressor(n_estimators=300,\n",
    "                                     max_depth=150,\n",
    "                                     criterion='mae',\n",
    "                                     learning_rate=0.1,\n",
    "                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# afficher les scores et prédictions vs test associées\n",
    "base_rf_score = evaluate('GBM_base', GBM_base, sel, sel_features, 'SiteEnergyUse(kBtu)', 0.25, 'N_D_BuildingType', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. xGBoost regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un modèle xGboost\n",
    "xgb_base = xgb.XGBModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_base.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_base = xgb.XGBModel(max_depth=150, n_estimators=300, objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher les scores et prédictions vs test associées\n",
    "xgb_score = evaluate('xgb_base', xgb_base, sel, sel_features, 'SiteEnergyUse(kBtu)', 0.25, 'N_D_BuildingType', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Confronter le modèle retenu à des données test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isoler des bâtiments pour validation\n",
    "buldings_in15not16 = pd.read_csv('in15not16.csv')\n",
    "buldings_in16not15 = pd.read_csv('in16not15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features de résultats : 4 cibles possibles\n",
    "Results = ['SiteEUI(kBtu/sf)',\n",
    "           'SiteEnergyUse(kBtu)',\n",
    "           'TotalGHGEmissions',\n",
    "           'GHGEmissionsIntensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirer les outliers\n",
    "for i in Results:\n",
    "    sel = sel[sel[i] <= sel[i].quantile(0.99)]\n",
    "    sel = sel[sel[i] >= sel[i].quantile(0.01)]\n",
    "    print(sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un jeu de données validation\n",
    "valid1 = sel[sel['OSEBuildingID'].isin(buldings_in16not15['OSEBuildingID'])]\n",
    "valid2 = sel[sel['OSEBuildingID'].isin(buldings_in15not16['OSEBuildingID'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaténer les données \n",
    "valid = pd.concat([valid1, valid2], sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = sel[~sel['OSEBuildingID'].isin(buldings_in16not15['OSEBuildingID'])]\n",
    "sel = sel[~sel['OSEBuildingID'].isin(buldings_in16not15['OSEBuildingID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le modèle retenu est le random forest avec une sélection \"sobre\" de features, on fit de nouveau ce modèle, mais hors données de test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Appliquer le Best Model  - Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélectionner les arguments de la fonction d'évaluation\n",
    "# les features dérivés et les features numériques traités\n",
    "sel_features = sel.columns[\n",
    "    sel.columns.str.contains('N_RG_') |\n",
    "    sel.columns.str.contains('N_D_')]\n",
    "print(sel_features.size)\n",
    "# la cible prise en référence est \n",
    "sel_target = 'SiteEnergyUse(kBtu)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# définition des plages de variation des hyperparamètres\n",
    "n_estimators = [int(x) for x in np.linspace(start=300, stop=500, num=3)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(130, 190, num=7)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 3]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la grid : random_grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélection des features et de la cible (une seule cible)\n",
    "features = sel[sel_features]\n",
    "labels = np.log(sel[sel_target])\n",
    "\n",
    "# split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=sel['N_D_BuildingType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer d'un modèle et RandomizedSearchCV des hyperparamètres\n",
    "# avec 3 folds de cross validation\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator=rf,\n",
    "                               param_distributions=random_grid,\n",
    "                               n_iter=100,\n",
    "                               cv=3,\n",
    "                               verbose=2,\n",
    "                               random_state=42,\n",
    "                               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entraîner le modèle pour déterminer les meilleurs paramètres\n",
    "rf_random.fit(train_features, train_labels)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# appliquer les meilleurs paramètres\n",
    "best_random = rf_random.best_estimator_\n",
    "random_score = evaluate('best_random', best_random, sel, sel_features, sel_target, 0.25, 'N_D_BuildingType', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- excellente surprise au passage d'observer un meilleur score pour ce découpage spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélection des features et de la cible\n",
    "features = valid[sel_features]\n",
    "# passage au log de la cible\n",
    "labels = np.log(valid[sel_target])\n",
    "# calcul des predictions\n",
    "predictions = best_random.predict(features)\n",
    "# retour aux valeurs d'origine\n",
    "test = np.exp(labels)\n",
    "predict = np.exp(predictions)\n",
    "# évaluation selon r2 et rmse\n",
    "r2 = r2_score(test, predict)\n",
    "# affichage du score r2\n",
    "print('r2: {:.2f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage Test vs Predictions\n",
    "g = sns.jointplot(\n",
    "    test,\n",
    "    predict,\n",
    "    kind='reg',\n",
    "    stat_func=r2_score)\n",
    "g.ax_joint.set_xlabel(sel_target + ' - valid')\n",
    "g.ax_joint.set_ylabel(sel_target + ' - predicted')\n",
    "g.fig.suptitle(t='valid vs Prediction : '\n",
    "                   + str(sel_target),\n",
    "                   y=0,\n",
    "                   fontsize=16,\n",
    "                   alpha=0.75,\n",
    "                   weight='bold',\n",
    "                   ha='center')\n",
    "x0, x1 = g.ax_joint.get_xlim()\n",
    "y0, y1 = g.ax_joint.get_ylim()\n",
    "lims = [max(x0, y0), min(x1, y1)]\n",
    "g.ax_joint.plot(lims, lims, ':k')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
